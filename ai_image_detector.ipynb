{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guyfloki/ai-image-detector/blob/main/ai_image_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvle7WrWh_El",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**DOWNLOAD** **ZIP** **AND** **CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XEYxNOL9gzsB",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stone\\.conda\\envs\\image-detector\\lib\\site-packages\\gdown\\__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Error:\n",
      "\n",
      "\tHTTPSConnectionPool(host='drive.google.com', port=443): Max retries\n",
      "\texceeded with url: /uc?id=1-1ddgedsRSvJm3ERQwJPy4tq4cB0uWe9 (Caused by\n",
      "\tConnectTimeoutError(<urllib3.connection.HTTPSConnection object at\n",
      "\t0x00000235E1FAFC40>, 'Connection to drive.google.com timed out.\n",
      "\t(connect timeout=None)'))\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n"
     ]
    }
   ],
   "source": [
    "#If it does not downloading due to high traffic on the file, please use directly link.\n",
    "#Train.zip\n",
    "!gdown --id 1-1ddgedsRSvJm3ERQwJPy4tq4cB0uWe9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LjfRuOrg5ME",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Test.zip\n",
    "!gdown --id 1-1xneYPH9fgSPCVnlZrhCM6c0FpFEl6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaovvWU0g6H6",
    "outputId": "c79d612a-3894-41b9-af92-6c30102e85d2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Train.csv\n",
    "!gdown --id 1rM2r7cxve7ApXCHTlBnMyD50n5hfnoAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnMYru-_g62J",
    "outputId": "a01dd54c-f138-4403-fc17-bdf860af35d2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Test.csv\n",
    "!gdown --id 1-GzzsszBlrmUHaDvoqVJgFfLvzRQDaBV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLus1puriAQN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**UNZIP** **FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHXyASREhXOU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!unzip /content/Train.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FsPwSGFGhcGZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!unzip /content/Test.zip -d /content/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLaAct_EiQV-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**CHECK** **SYSTEM** **DETAILS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_0ZUvzjAME0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8FxYgfm6AOkp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 23 19:43:11 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.41                 Driver Version: 531.41       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti    WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   33C    P8               23W / 250W|   1553MiB / 11264MiB |     11%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      9448    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     11544    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     12300    C+G   C:\\Program Files\\LGHUB\\lghub.exe          N/A      |\n",
      "|    0   N/A  N/A     12912    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13352    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14056    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15432    C+G   ...B\\system_tray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     15588    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe    N/A      |\n",
      "|    0   N/A  N/A     16392    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     18564    C+G   ....5390.0_x64__8j3eq9eme6ctt\\IGCC.exe    N/A      |\n",
      "|    0   N/A  N/A     18688    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n",
      "|    0   N/A  N/A     19332    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     19744    C+G   ..._m7qx9dzpwqaze\\app\\Twinkle Tray.exe    N/A      |\n",
      "|    0   N/A  N/A     20264    C+G   ...Files\\ManicTime\\ManicTimeClient.exe    N/A      |\n",
      "|    0   N/A  N/A     20316    C+G   ...796_x64__8wekyb3d8bbwe\\ms-teams.exe    N/A      |\n",
      "|    0   N/A  N/A     21132    C+G   ...on\\122.0.2365.92\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     22908    C+G   ...on\\122.0.2365.92\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     27668    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     29452    C+G   ...9\\extracted\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     33100    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     35584    C+G   D:\\Typora\\Typora.exe                      N/A      |\n",
      "|    0   N/A  N/A     35632    C+G   D:\\CloudMusic\\cloudmusic.exe              N/A      |\n",
      "|    0   N/A  N/A     42880    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     46244    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uW1u9_vHiWS5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**MAIN** **PROCESS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZ9ijMdHPRZ1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7tt0jGdQgN5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer, AutoImageProcessor, EarlyStoppingCallback,AutoFeatureExtractor\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef, cohen_kappa_score, log_loss\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoFeatureExtractor, CvtForImageClassification\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v04nraR3wMIj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**PREPARE** **DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rA2gKZbK0XAB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.loc[idx, 'image_path']\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.data.loc[idx, 'target'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8EKJTwCah6W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_class_weights(n_samples_class0, n_samples_class1):\n",
    "    total = n_samples_class0 + n_samples_class1\n",
    "    weight_class0 = total / (2 * n_samples_class0)\n",
    "    weight_class1 = total / (2 * n_samples_class1)\n",
    "    return weight_class0, weight_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v80AZMZE0hwL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Y2E7R_n0_BT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = CustomDataset(\"/content/train.csv\", transform=transform)\n",
    "test_data = CustomDataset(\"/content/test.csv\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0Q-UFtPa86a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_samples_class0 = sum(train_data.data[\"target\"] == 0.0)\n",
    "n_samples_class1 = sum(train_data.data[\"target\"] == 1.0)\n",
    "weight_class0, weight_class1 = compute_class_weights(n_samples_class0, n_samples_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqQR5Qo5a_Vp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "samples_weights = [weight_class0 if label == 0.0 else weight_class1 for label in train_data.data[\"target\"]]\n",
    "weighted_sampler = WeightedRandomSampler(samples_weights, len(samples_weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2pBXEimbBFe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=128, sampler=weighted_sampler, num_workers=6, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=6, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcvqkgoiwItY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**MODEL** **DEFINITION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkLCW2a1zGzI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOMSeNOcbw01",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([weight_class0, weight_class1]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dUwARBhh2Xd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = CvtForImageClassification.from_pretrained('microsoft/cvt-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOkUwHpnW_St",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomClassifier, self).__init__()\n",
    "        # First Hidden Layer\n",
    "        self.fc1 = nn.Linear(384, 256)\n",
    "        self.mish1 = nn.Mish(inplace=False)\n",
    "        self.norm1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Second Hidden Layer\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.mish2 = nn.Mish(inplace=False)\n",
    "        self.norm2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "\n",
    "        # Output Layer\n",
    "        self.fc_out = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.norm1(self.mish1(self.fc1(x))))\n",
    "        x = self.dropout2(self.norm2(self.mish2(self.fc2(x))))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "model.classifier = CustomClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6jimbK02uW1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999), weight_decay=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNiPizkXPioz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QakiEOo-PKXz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**MAIN** **TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPZbEcEq27EI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#change path for your own\n",
    "list_of_files = glob.glob('/content/drive/MyDrive/CVT-13_2/model_epoch_*.pth')\n",
    "if list_of_files:  # Check if the list is not empty\n",
    "    # Identify the latest model\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "    # Load the latest model\n",
    "    checkpoint = torch.load(latest_file)\n",
    "    train_losses = checkpoint['train_losses']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    starting_epoch = checkpoint['epoch'] + 1\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = 1e-5\n",
    "    # Load the average loss\n",
    "    avg_loss_loaded = checkpoint.get('avg_loss', None)  # Use None if avg_loss is not found\n",
    "\n",
    "    model.train()  # or model.eval() if you are doing evaluation instead of training\n",
    "    total_epochs = 50\n",
    "else:\n",
    "    # If no saved model, start from epoch 1\n",
    "    total_epochs = 50\n",
    "    starting_epoch = 0\n",
    "    avg_loss_loaded = None\n",
    "    train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ph80_xEF27EQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckNuTzm97Ou-",
    "outputId": "6bdb3a1f-6040-4ed2-88d4-4a90cd7b0229",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "for g in optimizer.param_groups:\n",
    "  print(g['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNtGUiwx2tpb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(starting_epoch, total_epochs):\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1}, Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}\", unit=\"batch\") as progress_bar:\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.logits, labels)\n",
    "\n",
    "            # Gradient clipping\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"Loss\": loss.item()})\n",
    "            progress_bar.update()\n",
    "\n",
    "            # Free up memory\n",
    "            del inputs, labels, outputs\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch {epoch+1} - Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'avg_loss': avg_train_loss,\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        #change path for your own\n",
    "    }, f\"/content/drive/MyDrive/CVT-13_2/model_epoch_{epoch}.pth\")\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW0Qc8KC4zTS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "se6sXb242trq",
    "outputId": "a476b913-08c1-4905-dc8a-4eacdd6df353",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 1978/1978 [07:54<00:00,  4.17batch/s, Test Loss=1.33e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.1275\n",
      "Accuracy: 98.54%\n",
      "Precision: 0.99\n",
      "Recall: 0.98\n",
      "F1 Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "# Assuming your training loop code ends before this\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # Disables gradient calculation for evaluation, which reduces memory usage\n",
    "    with tqdm(total=len(test_loader), desc=\"Evaluation\", unit=\"batch\") as progress_bar:\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with autocast():  # Use autocast if you're evaluating with mixed precision\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.logits, labels)  # Assuming your model outputs logits\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.logits.max(1)  # Get the index of the max log-probability\n",
    "            all_predicted.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            progress_bar.set_postfix({\"Test Loss\": loss.item()})\n",
    "            progress_bar.update()\n",
    "\n",
    "# Convert all_labels and all_predicted to numpy arrays if they are not already\n",
    "all_labels = np.array(all_labels)\n",
    "all_predicted = np.array(all_predicted)\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "accuracy = accuracy_score(all_labels, all_predicted)\n",
    "precision = precision_score(all_labels, all_predicted, average='macro')\n",
    "recall = recall_score(all_labels, all_predicted, average='macro')\n",
    "f1 = f1_score(all_labels, all_predicted, average='macro')\n",
    "\n",
    "print(f'Average Test Loss: {avg_test_loss:.4f}')\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF4JH8VctNqa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predicted)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=False)  # You can set show_normed to True to show percentages\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "plt.savefig(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYYA8dQ8gDET",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming train_losses is a list that contains the average loss of each epoch\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EWEaDbTvxtD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**MAKE** **PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6to2zSQJFjx1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbMF1rge2tuA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to load an image from a URL\n",
    "def load_image_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "# URL of your custom image\n",
    "image_url = \"\"\n",
    "\n",
    "# Load and transform your custom image\n",
    "custom_image = load_image_from_url(image_url)\n",
    "transformed_image = transform(custom_image).unsqueeze(0)  # Add batch dimension\n",
    "transformed_image = transformed_image.to(device)\n",
    "\n",
    "# Evaluate the custom image using the model\n",
    "model.eval()\n",
    "with torch.no_grad():  # Disables gradient calculation for evaluation\n",
    "    # If you're using autocast for mixed precision\n",
    "    with torch.cuda.amp.autocast():\n",
    "        outputs = model(transformed_image)\n",
    "        # Use the logits attribute to get the prediction scores\n",
    "        logits = outputs.logits\n",
    "        _, predicted = logits.max(1)  # Get the index of the max log-probability\n",
    "\n",
    "# Print the prediction\n",
    "print(f'Predicted class: {predicted.item()}')\n",
    "\n",
    "# If you want to get the probabilities\n",
    "probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "print(f'Class probabilities: {probabilities}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOGSaj/33Cb4cbiBepIkUO0",
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}